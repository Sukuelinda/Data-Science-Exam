---
# IMPORTANT: Change settings here, but DO NOT change the spacing.
# Remove comments and add values where applicable.
# The descriptions below should be self-explanatory

title: "An analytical briefing on content trends, audience preferences, and production dynamics"
#subtitle: "This will appear as Right Header"

documentclass: "elsarticle"

# --------- Thesis title (Optional - set to FALSE by default).
# You can move the details below around as you please.
Thesis_FP: FALSE
# Entry1: "An unbelievable study with a title spanning multiple lines."
# Entry2: "\\textbf{Some Guy}" # textbf for bold
# Entry3: "A thesis submitted toward the degree of Doctor of Philosophy"
# Uni_Logo: Tex/Logo.png # Place a logo in the indicated location (from your root, e.g. defaults to ~/Tex/Logo.png) and uncomment this line. Leave uncommented for no image
# Logo_width: 0.3 # If using a logo - use this to set width (size) of image
# Entry4: "Under the supervision of: \\vfill Prof. Joe Smith and Dr. Frank Smith"
# Entry5: "Stellenbosch University"
# Entry6: April 2020
# Entry7:
# Entry8:

# --------- Front Page
# Comment: ----- Follow this pattern for up to 5 authors
AddTitle: TRUE # Use FALSE when submitting to peer reviewed platform. This will remove author names.
Author1: "Linda Dube"
Ref1: "Stellenbosch University, Western Cape" # First Author's Affiliation
Email1: "23084103\\@sun.ac.za" # First Author's Email address



# ----- Manage headers and footers:
#BottomLFooter: $Title$
#BottomCFooter:
#TopLHeader: \leftmark # Adds section name at topleft. Remove comment to add it.
BottomRFooter: "\\footnotesize Page \\thepage" # Add a '#' before this line to remove footer.
addtoprule: TRUE
addfootrule: TRUE               # Use if footers added. Add '#' to remove line.

# --------- page margins:
margin: 2.3 # Sides
bottom: 2 # bottom
top: 2.5 # Top
HardSet_layout: TRUE # Hard-set the spacing of words in your document. This will stop LaTeX squashing text to fit on pages, e.g.
# This is done by hard-setting the spacing dimensions. Set to FALSE if you want LaTeX to optimize this for your paper.

# --------- Line numbers
linenumbers: FALSE # Used when submitting to journal

# ---------- References settings:
# You can download cls format here: https://www.zotero.org/ - simply search for your institution. You can also edit and save cls formats here: https://editor.citationstyles.org/about/
# Hit download, store it in Tex/ folder, and change reference below - easy.
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
csl: Tex/harvard-stellenbosch-university.csl # referencing format used.
# By default, the bibliography only displays the cited references. If you want to change this, you can comment out one of the following:
#nocite: '@*' # Add all items in bibliography, whether cited or not
# nocite: |  # add specific references that aren't cited
#  @grinold2000
#  @Someoneelse2010

# ---------- General:
RemovePreprintSubmittedTo: TRUE  # Removes the 'preprint submitted to...' at bottom of titlepage
Journal: "Journal of Finance"   # Journal that the paper will be submitting to, if RemovePreprintSubmittedTo is set to TRUE.
toc: FALSE                       # Add a table of contents
numbersections: TRUE             # Should sections (and thus figures and tables) be numbered?
fontsize: 11pt                  # Set fontsize
linestretch: 1.2                # Set distance between lines.
link-citations: TRUE            # This creates dynamic links to the papers in reference list.

### Adding additional latex packages:
# header-includes:
#    - \usepackage{colortbl} # Add additional packages here.

output:
  pdf_document:
    keep_tex: TRUE
    template: Tex/TexDefault.txt
    fig_width: 3.5 # Adjust default figure sizes. This can also be done in the chunks of the text.
    fig_height: 3.5
abstract: |
  blabla
---



# Introduction \label{Introduction}


# Data  {-}
```{r}
titles <- readRDS("C:/Users/sukol/Documents/Masters frst semester/Data Science Exam/Data-Science-Exam/23084103_Datascience_Exam/Tex_Ex/23084103_Exam/Question 3/Tex_Ex/23084103_Netflix/data/netflix/titles.rds")

credits <- readRDS("C:/Users/sukol/Documents/Masters frst semester/Data Science Exam/Data-Science-Exam/23084103_Datascience_Exam/Tex_Ex/23084103_Exam/Question 3/Tex_Ex/23084103_Netflix/data/netflix/credits.rds")
movie_Info <- read.csv("C:/Users/sukol/Documents/Masters frst semester/Data Science Exam/Data-Science-Exam/23084103_Datascience_Exam/Tex_Ex/23084103_Exam/Question 3/Tex_Ex/23084103_Netflix/data/netflix/netflix_movies.csv")

# Save as CSV
write.csv(titles, "C:/Users/sukol/Documents/titles.csv", row.names = FALSE)
write.csv(credits, "C:/Users/sukol/Documents/credits.csv", row.names = FALSE)

titles_summary <- dfSummary(titles, plain.ascii = TRUE, style = "grid")
print(titles_summary)
credits_summary <- dfSummary(credits, plain.ascii = TRUE, style = "grid")
print(credits_summary)
movie_Info_summary <- dfSummary(movie_Info, plain.ascii = TRUE, style = "grid")
print(movie_Info_summary)

```

After using the dfSummary() function, we can conclude that the dataset is well-organized and clean. The summary output shows no duplicates, very few missing values, and consistent variable structures across over 6,000 entries. These indicators confirm that the dataset is reliable and ready for further analysis.

# Results and Analysis

## Average Popularity by Type


```{r Figure 1a, warning =  FALSE, fig.align = 'center', fig.cap = "Caption Here \\label{Figure1}", fig.height = 3, fig.width = 6, dev = 'png'}
library(dplyr)
library(ggplot2)

# Group and summarize by type
type_popularity <- titles %>%
  group_by(type) %>%
  summarise(avg_popularity = mean(tmdb_popularity, na.rm = TRUE),
            count = n()) %>%
  arrange(desc(avg_popularity))

# Bar plot
ggplot(type_popularity, aes(x = reorder(type, avg_popularity), y = avg_popularity, fill = type)) +
  geom_col(show.legend = FALSE) +
  labs(title = "Average TMDB Popularity by Type",
       x = "Content Type",
       y = "Average Popularity") +
  coord_flip() +
  theme_minimal()


```

The figure above shows that shows are, on average, more popular than movies based on TMDB popularity scores. This suggests that serialized content drives stronger viewer engagement than standalone films. The trend may be due to factors like binge-watching behavior, narrative depth, and global breakout shows. Given this, Netflix should prioritize investment in high-quality, locally relevant TV shows. Further analysis by country and genre can refine content strategy decisions.

## Popularity by Type and Country
```{r Figure 1b, warning =  FALSE, fig.align = 'center', fig.cap = "Caption Here \\label{Figure1}", fig.height = 3, fig.width = 6, dev = 'png'}
library(dplyr)
library(ggplot2)

# Aggregate average popularity by country and type
top_country_type <- titles %>%
  filter(!is.na(production_countries), !is.na(type)) %>%
  group_by(production_countries, type) %>%
  summarise(avg_popularity = mean(tmdb_popularity, na.rm = TRUE), .groups = "drop") %>%
  filter(production_countries != "") %>%
  top_n(20, avg_popularity)  # optional: limit to top 20 by popularity

# Grouped bar chart
ggplot(top_country_type, aes(x = reorder(production_countries, avg_popularity), y = avg_popularity, fill = type)) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(title = "Average Popularity of Netflix Shows vs Movies by Country",
       x = "Country", y = "Avg TMDB Popularity") +
  theme_minimal()




```

The analysis reveals that television shows originating from the United Kingdom (GB) and Sweden (SE) exhibit the highest average popularity among global audiences. This suggests a strong international appeal and production quality associated with series from these regions. In contrast, the United States (US) and Mexico (MX) lead in terms of movie popularity, indicating their dominant role in global film production. These findings highlight regional strengths in different content formats on Netflix.

\newpage


# Boxplot: Movie Length and IMDb Score by Country

```{r Figure 2, warning =  FALSE, fig.align = 'center', fig.cap = "Caption Here \\label{Figure1}", fig.height = 3, fig.width = 6, dev = 'png'}
library(dplyr)
library(ggplot2)
library(stringr)

# Clean country format: remove brackets and quotes
clean_movies <- titles %>%
  filter(type == "MOVIE",                         # match the exact casing
         !is.na(runtime),
         !is.na(imdb_score),
         !is.na(production_countries),
         runtime > 20, runtime < 300) %>%
  mutate(country = str_extract(production_countries, "[A-Z]{2}"))  # extract country code like US or GB

# Check number of rows after cleaning
cat("Cleaned movies:", nrow(clean_movies), "\n")

# Get top 5 countries by movie count
top_countries <- clean_movies %>%
  count(country, sort = TRUE) %>%
  slice_max(n, n = 5) %>%
  pull(country)

# Filter to those top 5 countries
filtered_movies <- clean_movies %>%
  filter(country %in% top_countries)

# Plot runtime
ggplot(filtered_movies, aes(x = country, y = runtime)) +
  geom_boxplot() +
  coord_flip() +
  labs(title = "Movie Runtime by Country",
       x = "Country",
       y = "Runtime (minutes)") +
  theme_minimal()

```

Interpret the box plot


\newpage

## Balance of actors vs. directors

```{r Figure 3a, warning =  FALSE, fig.align = 'center', fig.cap = "Caption Here \\label{Figure1}", fig.height = 3, fig.width = 6, dev = 'png'}
credits %>%
  count(role) %>%
  ggplot(aes(x = role, y = n, fill = role)) +
  geom_col() +
  labs(title = "Distribution of Credit Roles", y = "Count") +
  theme_minimal()


```
Are there more actors or directors per movie?


## For interests sakes: most credited actors or actresses
```{r Figure , warning =  FALSE, fig.align = 'center', fig.cap = "Caption Here \\label{Figure1}", fig.height = 3, fig.width = 6, dev = 'png'}

credits %>%
  count(name, sort = TRUE) %>%
  slice_head(n = 10)

```
who has more roles

# Conlusion


